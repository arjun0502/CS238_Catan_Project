{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catanatron import Game, Player, RandomPlayer, Color, ActionType\n",
    "from catanatron_gym.envs.catanatron_env import from_action_space, to_action_space\n",
    "from catanatron_gym.features import create_sample_vector\n",
    "import gymnasium as gym\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from collections import namedtuple, deque\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self, dim_state, num_actions, hidden_size):\n",
    "        super(DQN, self).__init__()\n",
    "        self.lin1 = nn.Linear(dim_state, hidden_size)\n",
    "        self.lin2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.lin3 = nn.Linear(hidden_size, num_actions)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = F.relu(self.lin2(x))\n",
    "        return self.lin3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition', ('state', 'action', 'next_state', 'reward', 'done'))\n",
    "\n",
    "class ReplayMemory(object):\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([], maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        self.memory.append(Transition(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_f(env, action):\n",
    "    action_type = action.action_type\n",
    "    reward = 0\n",
    "    if action_type == ActionType.BUILD_ROAD:\n",
    "       reward = .1\n",
    "    elif action_type == ActionType.BUILD_SETTLEMENT:\n",
    "       reward = .2\n",
    "    elif action_type == ActionType.BUILD_CITY:\n",
    "       reward = .3\n",
    "    if env.game.winning_color() == Color.BLUE:\n",
    "        reward = 1000\n",
    "    elif env.game.winning_color() is not None:\n",
    "        reward = -1000\n",
    "    return reward\n",
    "\n",
    "def state_tensor(state):\n",
    "    res = {k: state.player_state[k] for k in ('P0_ACTUAL_VICTORY_POINTS', 'P0_VICTORY_POINTS', 'P0_WOOD_IN_HAND', 'P0_BRICK_IN_HAND', 'P0_ORE_IN_HAND', 'P0_SHEEP_IN_HAND', 'P0_WHEAT_IN_HAND')}\n",
    "    for i in range(54):\n",
    "        building_feature = \"LOC_\" + str(i) + \"_HAS_BUILDING\"\n",
    "        if i in state.board.buildings:\n",
    "            res[building_feature] = True\n",
    "        else:\n",
    "            res[building_feature] = False\n",
    "    for i in range(72):\n",
    "        road_feature = \"LOC_\" + str(i) + \"_HAS_ROAD\"\n",
    "        if i in state.board.roads:\n",
    "            res[road_feature] = True\n",
    "        else:\n",
    "            res[road_feature] = False\n",
    "\n",
    "    return torch.tensor(list(res.values()), dtype=torch.float32).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_action(state, action_ints, policy_net, eps):\n",
    "    sample = random.random()\n",
    "    if sample > eps:\n",
    "        with torch.no_grad():\n",
    "            Q = policy_net(state)[0, action_ints]\n",
    "        return action_ints[Q.max(0).indices.item()]\n",
    "    else:\n",
    "        return random.choice(action_ints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAMMA = 0.9\n",
    "LR = 0.01\n",
    "BATCH_SIZE = 128\n",
    "HIDDEN_SIZE = 128\n",
    "TAU = .005\n",
    "\n",
    "POLICY_UPDATE = 1 # Number of actions before retraining\n",
    "TARGET_UPDATE = 1 # Number of episodes before updating target network\n",
    "NUM_EPISODES = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rishi/opt/anaconda3/envs/catan/lib/python3.11/site-packages/gymnasium/envs/registration.py:435: UserWarning: \u001b[33mWARN: The environment creator metadata doesn't include `render_modes`, contains: ['render.modes']\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"catanatron_gym:catanatron-v0\")\n",
    "state, info = env.reset()\n",
    "\n",
    "num_actions = env.action_space.n\n",
    "dim_state = state_tensor(env.game.state).shape[1]\n",
    "\n",
    "memory = ReplayMemory(10000)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# EPS_START = 0.9\n",
    "# EPS_END = 0.05\n",
    "# EPS_DECAY = 200\n",
    "# TARGET_UPDATE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_net = DQN(dim_state, num_actions, HIDDEN_SIZE).to(device)\n",
    "target_net = DQN(dim_state, num_actions, HIDDEN_SIZE).to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "target_net.eval()\n",
    "\n",
    "optimizer = optim.Adam(policy_net.parameters(), LR, amsgrad=True)\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    batch = Transition(*zip(*transitions))\n",
    "\n",
    "    states = torch.cat(batch.state)\n",
    "    actions = torch.tensor(batch.action)\n",
    "    next_states = torch.cat([state for state in batch.next_state if state is not None])\n",
    "    rewards = torch.tensor(batch.reward)\n",
    "    dones = torch.tensor(batch.done)\n",
    "\n",
    "    cur_Q = policy_net(states).gather(1, actions.unsqueeze(1)).squeeze(1)\n",
    "\n",
    "    target_Q = torch.zeros(BATCH_SIZE, device=device)\n",
    "    with torch.no_grad():\n",
    "        target_Q[~dones] = target_net(next_states).max(1).values\n",
    "    target_Q = rewards + GAMMA * target_Q\n",
    "\n",
    "    # Update the policy network\n",
    "    loss = F.mse_loss(cur_Q, target_Q)\n",
    "    print(\"Loss:\", loss.item())\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_value_(policy_net.parameters(), 100)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_episode():\n",
    "    env.reset()\n",
    "    state = state_tensor(env.game.state)\n",
    "    done = False\n",
    "    i = 0\n",
    "\n",
    "    while not done:\n",
    "        action_int = select_action(state, env.get_valid_actions(), policy_net, 0.5)\n",
    "        # action_int = random.choice(env.get_valid_actions())\n",
    "        action_struct = from_action_space(action_int, env.game.state.playable_actions)\n",
    "\n",
    "        _, _, done, _ = env.step(action_int)\n",
    "        reward = reward_f(env, action_struct)\n",
    "        next_state = state_tensor(env.game.state) if not done else None\n",
    "\n",
    "        memory.push(state, action_int, next_state, reward, done)\n",
    "        state = next_state\n",
    "\n",
    "        i += 1\n",
    "        if i % POLICY_UPDATE == 0:\n",
    "            train_batch()\n",
    "    print(i)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward: 0.2\n",
      "Loss: 2.5498762130737305\n",
      "Reward: 0.1\n",
      "Loss: 2.569211006164551\n",
      "Reward: 0.2\n",
      "Loss: 1.9969182014465332\n",
      "Reward: 0.1\n",
      "Loss: 2.1411640644073486\n",
      "Reward: 0\n",
      "Loss: 1.876656413078308\n",
      "Reward: 0\n",
      "Loss: 7815.42626953125\n",
      "Reward: 0\n",
      "Loss: 0.8467344045639038\n",
      "Reward: 0\n",
      "Loss: 15590.744140625\n",
      "Reward: 0\n",
      "Loss: 7788.66845703125\n",
      "Reward: 0\n",
      "Loss: 0.7628897428512573\n",
      "Reward: 0\n",
      "Loss: 0.6623737215995789\n",
      "Reward: 0\n",
      "Loss: 0.4462103843688965\n",
      "Reward: 0\n",
      "Loss: 0.46230024099349976\n",
      "Reward: 0\n",
      "Loss: 0.40422940254211426\n",
      "Reward: 0\n",
      "Loss: 0.3573697805404663\n",
      "Reward: 0\n",
      "Loss: 7813.20947265625\n",
      "Reward: 0\n",
      "Loss: 7764.36572265625\n",
      "Reward: 0\n",
      "Loss: 0.23999238014221191\n",
      "Reward: 0\n",
      "Loss: 7743.00146484375\n",
      "Reward: 0\n",
      "Loss: 0.26404422521591187\n",
      "Reward: 0\n",
      "Loss: 7821.513671875\n",
      "Reward: 0\n",
      "Loss: 0.24358396232128143\n",
      "Reward: 0\n",
      "Loss: 0.5576533079147339\n",
      "Reward: 0\n",
      "Loss: 0.2691742181777954\n",
      "Reward: 0\n",
      "Loss: 7638.966796875\n",
      "Reward: 0\n",
      "Loss: 0.3722044825553894\n",
      "Reward: 0\n",
      "Loss: 0.2417464405298233\n",
      "Reward: 0\n",
      "Loss: 0.34350359439849854\n",
      "Reward: 0\n",
      "Loss: 7526.2021484375\n",
      "Reward: 0\n",
      "Loss: 0.5484789609909058\n",
      "Reward: 0\n",
      "Loss: 0.8051797151565552\n",
      "Reward: 0\n",
      "Loss: 0.3605872392654419\n",
      "Reward: 0\n",
      "Loss: 0.1759037971496582\n",
      "Reward: 0\n",
      "Loss: 0.5133092999458313\n",
      "Reward: 0\n",
      "Loss: 1.1528741121292114\n",
      "Reward: 0\n",
      "Loss: 5.579766750335693\n",
      "Reward: 0\n",
      "Loss: 1.4785501956939697\n",
      "Reward: 0\n",
      "Loss: 1.1365796327590942\n",
      "Reward: 0\n",
      "Loss: 7177.494140625\n",
      "Reward: 0\n",
      "Loss: 0.7899394035339355\n",
      "Reward: 0\n",
      "Loss: 2.199997901916504\n",
      "Reward: 0\n",
      "Loss: 0.6128302216529846\n",
      "Reward: 0\n",
      "Loss: 1.3831056356430054\n",
      "Reward: 0\n",
      "Loss: 12.93956184387207\n",
      "Reward: 0\n",
      "Loss: 7839.45556640625\n",
      "Reward: 0\n",
      "Loss: 1.675035834312439\n",
      "Reward: 0\n",
      "Loss: 1.304349660873413\n",
      "Reward: 0\n",
      "Loss: 3.147285223007202\n",
      "Reward: 0\n",
      "Loss: 4.080780029296875\n",
      "Reward: 0\n",
      "Loss: 1.9665133953094482\n",
      "Reward: 0\n",
      "Loss: 11.578817367553711\n",
      "Reward: 0\n",
      "Loss: 1.4005576372146606\n",
      "Reward: 0\n",
      "Loss: 7812.142578125\n",
      "Reward: 0\n",
      "Loss: 0.7725224494934082\n",
      "Reward: 0\n",
      "Loss: 6690.78564453125\n",
      "Reward: 0\n",
      "Loss: 1.6817578077316284\n",
      "Reward: 0\n",
      "Loss: 7801.814453125\n",
      "Reward: 0\n",
      "Loss: 2.891051769256592\n",
      "Reward: 0\n",
      "Loss: 9.1953763961792\n",
      "Reward: 0\n",
      "Loss: 3.484713077545166\n",
      "Reward: 0\n",
      "Loss: 2.876758337020874\n",
      "Reward: 0\n",
      "Loss: 6370.09375\n",
      "Reward: 0\n",
      "Loss: 1.2096045017242432\n",
      "Reward: 0\n",
      "Loss: 13990.8603515625\n",
      "Reward: 0\n",
      "Loss: 2.5812060832977295\n",
      "Reward: 0\n",
      "Loss: 1.9334216117858887\n",
      "Reward: 0\n",
      "Loss: 0.8471353054046631\n",
      "Reward: 0\n",
      "Loss: 2.326680898666382\n",
      "Reward: 0\n",
      "Loss: 5.766759872436523\n",
      "Reward: 0\n",
      "Loss: 8.255962371826172\n",
      "Reward: 0\n",
      "Loss: 7.000291347503662\n",
      "Reward: 0\n",
      "Loss: 3.1814074516296387\n",
      "Reward: 0\n",
      "Loss: 12.56593132019043\n",
      "Reward: 0\n",
      "Loss: 1.3517208099365234\n",
      "Reward: 0\n",
      "Loss: 3.5294623374938965\n",
      "Reward: 0\n",
      "Loss: 7838.4541015625\n",
      "Reward: 0\n",
      "Loss: 3.828077793121338\n",
      "Reward: 0\n",
      "Loss: 0.9208055734634399\n",
      "Reward: 0\n",
      "Loss: 12974.9150390625\n",
      "Reward: 0\n",
      "Loss: 1.7242435216903687\n",
      "Reward: 0.3\n",
      "Loss: 0.7942789793014526\n",
      "Reward: 0\n",
      "Loss: 1.7783913612365723\n",
      "Reward: 0\n",
      "Loss: 9.205577850341797\n",
      "Reward: 0\n",
      "Loss: 4749.1044921875\n",
      "Reward: 0\n",
      "Loss: 4.377333164215088\n",
      "Reward: 0\n",
      "Loss: 3.9095053672790527\n",
      "Reward: 0\n",
      "Loss: 6.887959957122803\n",
      "Reward: 0\n",
      "Loss: 4.401370048522949\n",
      "Reward: 0\n",
      "Loss: 13.583291053771973\n",
      "Reward: 0\n",
      "Loss: 7821.21240234375\n",
      "Reward: 0\n",
      "Loss: 12.641031265258789\n",
      "Reward: 0\n",
      "Loss: 7816.04541015625\n",
      "Reward: 0\n",
      "Loss: 1.0731972455978394\n",
      "Reward: 0\n",
      "Loss: 3.8171634674072266\n",
      "Reward: 0\n",
      "Loss: 5.574784278869629\n",
      "Reward: 0\n",
      "Loss: 11686.9951171875\n",
      "Reward: 0\n",
      "Loss: 11.669008255004883\n",
      "Reward: 0\n",
      "Loss: 3686.68505859375\n",
      "Reward: 0\n",
      "Loss: 5.631255626678467\n",
      "Reward: 0\n",
      "Loss: 1.6511716842651367\n",
      "Reward: 0\n",
      "Loss: 15.1947660446167\n",
      "Reward: 0\n",
      "Loss: 7819.6123046875\n",
      "Reward: 0\n",
      "Loss: 8.074939727783203\n",
      "Reward: 0\n",
      "Loss: 11.931429862976074\n",
      "Reward: 0\n",
      "Loss: 16.851234436035156\n",
      "Reward: 0\n",
      "Loss: 3.170544147491455\n",
      "Reward: 0\n",
      "Loss: 3.3635330200195312\n",
      "Reward: 0\n",
      "Loss: 4.155453681945801\n",
      "Reward: 0\n",
      "Loss: 2729.624267578125\n",
      "Reward: 0\n",
      "Loss: 7802.7666015625\n",
      "Reward: 0\n",
      "Loss: 9.367772102355957\n",
      "Reward: 0\n",
      "Loss: 7799.00244140625\n",
      "Reward: 0\n",
      "Loss: 3.916823387145996\n",
      "Reward: 0\n",
      "Loss: 30.36588478088379\n",
      "Reward: 0\n",
      "Loss: 5.784558296203613\n",
      "Reward: 0\n",
      "Loss: 2182.76220703125\n",
      "Reward: 0\n",
      "Loss: 15.1293306350708\n",
      "Reward: 0\n",
      "Loss: 8.539773941040039\n",
      "Reward: 0\n",
      "Loss: 4.076684474945068\n",
      "Reward: 0\n",
      "Loss: 7796.0439453125\n",
      "Reward: 0\n",
      "Loss: 2.170910358428955\n",
      "Reward: 0\n",
      "Loss: 11.464815139770508\n",
      "Reward: 0\n",
      "Loss: 7.659476280212402\n",
      "Reward: 0\n",
      "Loss: 20.482481002807617\n",
      "Reward: 0.1\n",
      "Loss: 1588.139892578125\n",
      "Reward: 0.1\n",
      "Loss: 7.489982604980469\n",
      "Reward: 0\n",
      "Loss: 7822.66357421875\n",
      "Reward: 0\n",
      "Loss: 22.66717529296875\n",
      "Reward: 0\n",
      "Loss: 9.892291069030762\n",
      "Reward: 0\n",
      "Loss: 14.26852035522461\n",
      "Reward: 0\n",
      "Loss: 7.0145111083984375\n",
      "Reward: 0\n",
      "Loss: 9.620596885681152\n",
      "Reward: 0\n",
      "Loss: 4.155223846435547\n",
      "Reward: 0\n",
      "Loss: 19.34735870361328\n",
      "Reward: 0\n",
      "Loss: 7809.60205078125\n",
      "Reward: 0\n",
      "Loss: 8826.306640625\n",
      "Reward: 0\n",
      "Loss: 7796.35498046875\n",
      "Reward: 0\n",
      "Loss: 8.60120964050293\n",
      "Reward: 0\n",
      "Loss: 2.5622994899749756\n",
      "Reward: 0\n",
      "Loss: 33.43704605102539\n",
      "Reward: 0\n",
      "Loss: 24.32805633544922\n",
      "Reward: 0\n",
      "Loss: 25.168045043945312\n",
      "Reward: 0\n",
      "Loss: 38.05048751831055\n",
      "Reward: 0\n",
      "Loss: 7786.26123046875\n",
      "Reward: 0\n",
      "Loss: 10.63687515258789\n",
      "Reward: 0\n",
      "Loss: 8469.212890625\n",
      "Reward: 0\n",
      "Loss: 2.0123953819274902\n",
      "Reward: 0\n",
      "Loss: 4.765707969665527\n",
      "Reward: 0\n",
      "Loss: 8.895928382873535\n",
      "Reward: 0\n",
      "Loss: 5.603201866149902\n",
      "Reward: 0\n",
      "Loss: 8.691621780395508\n",
      "Reward: 0.3\n",
      "Loss: 18.722461700439453\n",
      "Reward: 0\n",
      "Loss: 10.92809772491455\n",
      "Reward: 0\n",
      "Loss: 7761.7373046875\n",
      "Reward: 0\n",
      "Loss: 15.132254600524902\n",
      "Reward: 0\n",
      "Loss: 6.904506683349609\n",
      "Reward: 0\n",
      "Loss: 8.102805137634277\n",
      "Reward: 0\n",
      "Loss: 6.752671241760254\n",
      "Reward: 0\n",
      "Loss: 7731.2138671875\n",
      "Reward: 0\n",
      "Loss: 8.740668296813965\n",
      "Reward: 0\n",
      "Loss: 297.2757873535156\n",
      "Reward: 0\n",
      "Loss: 84.85165405273438\n",
      "Reward: 0\n",
      "Loss: 12.273722648620605\n",
      "Reward: 0\n",
      "Loss: 18.628589630126953\n",
      "Reward: 0\n",
      "Loss: 40.172080993652344\n",
      "Reward: 0\n",
      "Loss: 35.72699737548828\n",
      "Reward: 0\n",
      "Loss: 7738.5908203125\n",
      "Reward: 0\n",
      "Loss: 7727.49853515625\n",
      "Reward: 0\n",
      "Loss: 7.072207450866699\n",
      "Reward: 0\n",
      "Loss: 10.713130950927734\n",
      "Reward: 0\n",
      "Loss: 179.95509338378906\n",
      "Reward: 0\n",
      "Loss: 13.484522819519043\n",
      "Reward: 0\n",
      "Loss: 48.00108337402344\n",
      "Reward: 0\n",
      "Loss: 42.69943618774414\n",
      "Reward: 0\n",
      "Loss: 7771.7001953125\n",
      "Reward: 0\n",
      "Loss: 26.971708297729492\n",
      "Reward: 0\n",
      "Loss: 47.17842483520508\n",
      "Reward: 0\n",
      "Loss: 38.010684967041016\n",
      "Reward: 0\n",
      "Loss: 122.26287841796875\n",
      "Reward: 0\n",
      "Loss: 17.70079803466797\n",
      "Reward: 0\n",
      "Loss: 7.404627799987793\n",
      "Reward: 0\n",
      "Loss: 7793.09521484375\n",
      "Reward: 0\n",
      "Loss: 33.45769119262695\n",
      "Reward: 0\n",
      "Loss: 23.681163787841797\n",
      "Reward: 0\n",
      "Loss: 17.64399528503418\n",
      "Reward: 0\n",
      "Loss: 6.30175256729126\n",
      "Reward: 0\n",
      "Loss: 9.668704986572266\n",
      "Reward: 0\n",
      "Loss: 7789.1669921875\n",
      "Reward: 0\n",
      "Loss: 9.513425827026367\n",
      "Reward: 0\n",
      "Loss: 25.354888916015625\n",
      "Reward: 0\n",
      "Loss: 16.666011810302734\n",
      "Reward: 0\n",
      "Loss: 135.73312377929688\n",
      "Reward: 0\n",
      "Loss: 96.96833038330078\n",
      "Reward: 0\n",
      "Loss: 7807.83984375\n",
      "Reward: 0.1\n",
      "Loss: 45.99721908569336\n",
      "Reward: 0\n",
      "Loss: 6.041627407073975\n",
      "Reward: 0\n",
      "Loss: 10.800958633422852\n",
      "Reward: 0\n",
      "Loss: 93.81161499023438\n",
      "Reward: 0\n",
      "Loss: 4.065574645996094\n",
      "Reward: 0\n",
      "Loss: 7.3986735343933105\n",
      "Reward: 0\n",
      "Loss: 28.696176528930664\n",
      "Reward: 0\n",
      "Loss: 9.906330108642578\n",
      "Reward: 0\n",
      "Loss: 19.808189392089844\n",
      "Reward: 0\n",
      "Loss: 42.02816390991211\n",
      "Reward: 0\n",
      "Loss: 2.3594613075256348\n",
      "Reward: 0\n",
      "Loss: 25.069461822509766\n",
      "Reward: 0\n",
      "Loss: 3.2336316108703613\n",
      "Reward: 0\n",
      "Loss: 10.970474243164062\n",
      "Reward: 0\n",
      "Loss: 8.940625190734863\n",
      "Reward: 0\n",
      "Loss: 5.3988566398620605\n",
      "Reward: 0\n",
      "Loss: 5.028722286224365\n",
      "Reward: 0\n",
      "Loss: 19.942710876464844\n",
      "Reward: 0\n",
      "Loss: 17.339344024658203\n",
      "Reward: 0\n",
      "Loss: 4.968012809753418\n",
      "Reward: 0\n",
      "Loss: 9.52430534362793\n",
      "Reward: 0\n",
      "Loss: 15.662496566772461\n",
      "Reward: 0\n",
      "Loss: 7803.89794921875\n",
      "Reward: 0\n",
      "Loss: 6.035923957824707\n",
      "Reward: 0\n",
      "Loss: 10.029775619506836\n",
      "Reward: 0\n",
      "Loss: 7793.97412109375\n",
      "Reward: 0\n",
      "Loss: 6.134134769439697\n",
      "Reward: 0\n",
      "Loss: 4.238020896911621\n",
      "Reward: 0\n",
      "Loss: 10.777732849121094\n",
      "Reward: 0\n",
      "Loss: 2.4644744396209717\n",
      "Reward: 0\n",
      "Loss: 3.1344897747039795\n",
      "Reward: 0\n",
      "Loss: 6.113258361816406\n",
      "Reward: 0\n",
      "Loss: 6.056344032287598\n",
      "Reward: 0\n",
      "Loss: 3.3290023803710938\n",
      "Reward: 0\n",
      "Loss: 5.606026649475098\n",
      "Reward: 0\n",
      "Loss: 9.71968936920166\n",
      "Reward: 0\n",
      "Loss: 10.788716316223145\n",
      "Reward: 0\n",
      "Loss: 2.6250391006469727\n",
      "Reward: 0\n",
      "Loss: 3.8768911361694336\n",
      "Reward: 0\n",
      "Loss: 5.629055500030518\n",
      "Reward: 0.1\n",
      "Loss: 7784.6142578125\n",
      "Reward: 0\n",
      "Loss: 1.0497515201568604\n",
      "Reward: 0\n",
      "Loss: 3.608328104019165\n",
      "Reward: 0\n",
      "Loss: 1.9282379150390625\n",
      "Reward: 0\n",
      "Loss: 2.323885679244995\n",
      "Reward: 0\n",
      "Loss: 1.524684190750122\n",
      "Reward: 0\n",
      "Loss: 1.5028928518295288\n",
      "Reward: 0\n",
      "Loss: 10.581087112426758\n",
      "Reward: 0\n",
      "Loss: 33.60679626464844\n",
      "Reward: 0\n",
      "Loss: 1.7697780132293701\n",
      "Reward: 0\n",
      "Loss: 1.512946367263794\n",
      "Reward: 0\n",
      "Loss: 1.6500561237335205\n",
      "Reward: 0\n",
      "Loss: 2.3142282962799072\n",
      "Reward: 0\n",
      "Loss: 11.913661003112793\n",
      "Reward: 0\n",
      "Loss: 4.2806172370910645\n",
      "Reward: 0\n",
      "Loss: 7.390160083770752\n",
      "Reward: 0\n",
      "Loss: 7.978470325469971\n",
      "Reward: 0\n",
      "Loss: 7782.8642578125\n",
      "Reward: 0\n",
      "Loss: 7.477427959442139\n",
      "Reward: 0\n",
      "Loss: 5.218846321105957\n",
      "Reward: 0\n",
      "Loss: 1.8307380676269531\n",
      "Reward: 0\n",
      "Loss: 3.3893916606903076\n",
      "Reward: 0\n",
      "Loss: 7782.4501953125\n",
      "Reward: 0.1\n",
      "Loss: 7788.52197265625\n",
      "Reward: 0\n",
      "Loss: 1.4723948240280151\n",
      "Reward: 0\n",
      "Loss: 7784.86572265625\n",
      "Reward: 0\n",
      "Loss: 7.326042652130127\n",
      "Reward: 0\n",
      "Loss: 8.004855155944824\n",
      "Reward: 0\n",
      "Loss: 1.4930092096328735\n",
      "Reward: 0\n",
      "Loss: 1.4232298135757446\n",
      "Reward: 0\n",
      "Loss: 7784.658203125\n",
      "Reward: 0\n",
      "Loss: 2.9719221591949463\n",
      "Reward: 0\n",
      "Loss: 1.90029776096344\n",
      "Reward: 0\n",
      "Loss: 1.7425040006637573\n",
      "Reward: 0\n",
      "Loss: 1.4590959548950195\n",
      "Reward: 0\n",
      "Loss: 1.7694023847579956\n",
      "Reward: 0\n",
      "Loss: 21.864253997802734\n",
      "Reward: 0\n",
      "Loss: 1.3766851425170898\n",
      "Reward: 0\n",
      "Loss: 2.3714065551757812\n",
      "Reward: 0\n",
      "Loss: 3.8136394023895264\n",
      "Reward: 0\n",
      "Loss: 1.7872397899627686\n",
      "Reward: 0\n",
      "Loss: 2.8136680126190186\n",
      "Reward: 0\n",
      "Loss: 7781.36328125\n",
      "Reward: 0\n",
      "Loss: 1.4227606058120728\n",
      "Reward: 0\n",
      "Loss: 311.2751159667969\n",
      "Reward: 0\n",
      "Loss: 1.485693335533142\n",
      "Reward: 0\n",
      "Loss: 1.546242356300354\n",
      "Reward: 0\n",
      "Loss: 1.563440203666687\n",
      "Reward: 0\n",
      "Loss: 35.25746536254883\n",
      "Reward: 0\n",
      "Loss: 7784.0888671875\n",
      "Reward: 0\n",
      "Loss: 2.911623954772949\n",
      "Reward: 0\n",
      "Loss: 1.8802971839904785\n",
      "Reward: 0\n",
      "Loss: 1.9397627115249634\n",
      "Reward: 0\n",
      "Loss: 1.6295663118362427\n",
      "Reward: 0\n",
      "Loss: 35.950714111328125\n",
      "Reward: 0\n",
      "Loss: 2.006061553955078\n",
      "Reward: 0\n",
      "Loss: 2.0401148796081543\n",
      "Reward: 0\n",
      "Loss: 7781.25537109375\n",
      "Reward: 0\n",
      "Loss: 2.5637710094451904\n",
      "Reward: 0\n",
      "Loss: 7781.35791015625\n",
      "Reward: 0\n",
      "Loss: 2.0223517417907715\n",
      "Reward: 0\n",
      "Loss: 16.833288192749023\n",
      "Reward: 0\n",
      "Loss: 12.02876091003418\n",
      "Reward: 0\n",
      "Loss: 7780.76025390625\n",
      "Reward: 0\n",
      "Loss: 7780.49365234375\n",
      "Reward: 0\n",
      "Loss: 1.8409123420715332\n",
      "Reward: 0\n",
      "Loss: 1.6829273700714111\n",
      "Reward: 0\n",
      "Loss: 3.4559485912323\n",
      "Reward: 0\n",
      "Loss: 18.39503288269043\n",
      "Reward: 0\n",
      "Loss: 7781.2763671875\n",
      "Reward: 0\n",
      "Loss: 1.8321305513381958\n",
      "Reward: 0\n",
      "Loss: 1.8989312648773193\n",
      "Reward: 0\n",
      "Loss: 1.774350643157959\n",
      "Reward: 0\n",
      "Loss: 13.981202125549316\n",
      "Reward: 0\n",
      "Loss: 2.0105440616607666\n",
      "Reward: 0\n",
      "Loss: 1.8951526880264282\n",
      "Reward: 0\n",
      "Loss: 2.2966818809509277\n",
      "Reward: 0\n",
      "Loss: 3.2742092609405518\n",
      "Reward: 0\n",
      "Loss: 2.2250685691833496\n",
      "Reward: 0\n",
      "Loss: 1.744757890701294\n",
      "Reward: 0\n",
      "Loss: 1.6351019144058228\n",
      "Reward: 0.1\n",
      "Loss: 7779.8203125\n",
      "Reward: 0.1\n",
      "Loss: 1.6455426216125488\n",
      "Reward: 0\n",
      "Loss: 1.9394391775131226\n",
      "Reward: 0\n",
      "Loss: 1.9111067056655884\n",
      "Reward: 0\n",
      "Loss: 2.0033700466156006\n",
      "Reward: 0\n",
      "Loss: 1.5834927558898926\n",
      "Reward: 0\n",
      "Loss: 5.0603556632995605\n",
      "Reward: 0\n",
      "Loss: 3.1329948902130127\n",
      "Reward: 0\n",
      "Loss: 2.8186213970184326\n",
      "Reward: 0\n",
      "Loss: 2.210846185684204\n",
      "Reward: 0\n",
      "Loss: 1.87615168094635\n",
      "Reward: 0\n",
      "Loss: 2.559030532836914\n",
      "Reward: 0\n",
      "Loss: 7779.57763671875\n",
      "Reward: 0\n",
      "Loss: 1.5672266483306885\n",
      "Reward: 0\n",
      "Loss: 2.1291394233703613\n",
      "Reward: 0\n",
      "Loss: 1.7023899555206299\n",
      "Reward: 0\n",
      "Loss: 2.8906009197235107\n",
      "Reward: 0\n",
      "Loss: 2.231886386871338\n",
      "Reward: 0\n",
      "Loss: 2.073870897293091\n",
      "Reward: 0\n",
      "Loss: 1.950305700302124\n",
      "Reward: 0\n",
      "Loss: 7779.89453125\n",
      "Reward: 0\n",
      "Loss: 1.5152668952941895\n",
      "Reward: 0\n",
      "Loss: 7779.91162109375\n",
      "Reward: 0\n",
      "Loss: 1.9758368730545044\n",
      "Reward: 0\n",
      "Loss: 1.9801182746887207\n",
      "Reward: 0\n",
      "Loss: 9.626343727111816\n",
      "Reward: 0\n",
      "Loss: 2.13749098777771\n",
      "Reward: 0\n",
      "Loss: 1.89568293094635\n",
      "Reward: 0\n",
      "Loss: 2.312713146209717\n",
      "Reward: 0\n",
      "Loss: 2.090015172958374\n",
      "Reward: 0\n",
      "Loss: 7778.9765625\n",
      "Reward: 0\n",
      "Loss: 2.373715400695801\n",
      "Reward: 0\n",
      "Loss: 1.4996827840805054\n",
      "Reward: 0\n",
      "Loss: 1.4618884325027466\n",
      "Reward: 0\n",
      "Loss: 2.0711171627044678\n",
      "Reward: 0\n",
      "Loss: 2.0311005115509033\n",
      "Reward: 0\n",
      "Loss: 7787.08837890625\n",
      "Reward: 0\n",
      "Loss: 7778.8916015625\n",
      "Reward: 0\n",
      "Loss: 7778.947265625\n",
      "Reward: 0\n",
      "Loss: 1.8995914459228516\n",
      "Reward: 0\n",
      "Loss: 1.8784722089767456\n",
      "Reward: 0\n",
      "Loss: 7778.47998046875\n",
      "Reward: 0\n",
      "Loss: 1.9654812812805176\n",
      "Reward: 0\n",
      "Loss: 2.3641045093536377\n",
      "Reward: 0\n",
      "Loss: 1.6015300750732422\n",
      "Reward: 0.1\n",
      "Loss: 2.0060009956359863\n",
      "Reward: 0\n",
      "Loss: 1.9870284795761108\n",
      "Reward: 0\n",
      "Loss: 7785.46142578125\n",
      "Reward: 0\n",
      "Loss: 7778.71875\n",
      "Reward: 0\n",
      "Loss: 2.0252761840820312\n",
      "Reward: 0\n",
      "Loss: 4.622864723205566\n",
      "Reward: 0\n",
      "Loss: 3.1603763103485107\n",
      "Reward: 0\n",
      "Loss: 2.3374106884002686\n",
      "Reward: 0\n",
      "Loss: 1.7405287027359009\n",
      "Reward: 0\n",
      "Loss: 1.8098320960998535\n",
      "Reward: 0\n",
      "Loss: 2.109090566635132\n",
      "Reward: 0\n",
      "Loss: 1.7045814990997314\n",
      "Reward: 0\n",
      "Loss: 7777.505859375\n",
      "Reward: 0\n",
      "Loss: 12.102692604064941\n",
      "Reward: 0\n",
      "Loss: 2.072343349456787\n",
      "Reward: 0\n",
      "Loss: 7777.69482421875\n",
      "Reward: 0\n",
      "Loss: 2.1264467239379883\n",
      "Reward: 0\n",
      "Loss: 2.4662985801696777\n",
      "Reward: 0\n",
      "Loss: 1.8517200946807861\n",
      "Reward: 0\n",
      "Loss: 5.835776329040527\n",
      "Reward: 0\n",
      "Loss: 7776.87744140625\n",
      "Reward: 0\n",
      "Loss: 2.1835694313049316\n",
      "Reward: 0\n",
      "Loss: 7777.34619140625\n",
      "Reward: 0\n",
      "Loss: 1.227695345878601\n",
      "Reward: 0\n",
      "Loss: 1.8743195533752441\n",
      "Reward: 0\n",
      "Loss: 2.784076690673828\n",
      "Reward: 0\n",
      "Loss: 2.299488067626953\n",
      "Reward: 0\n",
      "Loss: 1.7126444578170776\n",
      "Reward: 0\n",
      "Loss: 1.669527292251587\n",
      "Reward: 0\n",
      "Loss: 1.9139569997787476\n",
      "Reward: 0\n",
      "Loss: 2.2160775661468506\n",
      "Reward: 0\n",
      "Loss: 1.9872349500656128\n",
      "Reward: 0\n",
      "Loss: 1.5849077701568604\n",
      "Reward: 0\n",
      "Loss: 2.374582052230835\n",
      "Reward: 0\n",
      "Loss: 1.6027759313583374\n",
      "Reward: 0\n",
      "Loss: 2.2122342586517334\n",
      "Reward: 0\n",
      "Loss: 2.0558934211730957\n",
      "Reward: -1000\n",
      "Loss: 2.48335599899292\n",
      "398\n"
     ]
    }
   ],
   "source": [
    "train_episode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    for i in tqdm(range(NUM_EPISODES)):\n",
    "        train_episode()\n",
    "        if i % TARGET_UPDATE == 0:\n",
    "            target_net_state_dict = target_net.state_dict()\n",
    "            policy_net_state_dict = policy_net.state_dict()\n",
    "            for key in policy_net_state_dict:\n",
    "                target_net_state_dict[key] = policy_net_state_dict[key]*TAU + target_net_state_dict[key]*(1-TAU)\n",
    "            target_net.load_state_dict(target_net_state_dict)\n",
    "            target_net.eval()\n",
    "            # target_net.load_state_dict(policy_net.state_dict())\n",
    "            # target_net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPISODES = 10\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def select_action(state, eps):\n",
    "#     if random.random() < eps:\n",
    "#         return torch.tensor([[random.randrange(num_actions)]], device=device, dtype=torch.long)\n",
    "#     else:\n",
    "#         with torch.no_grad():\n",
    "#             return policy_net(state).max(1)[1].view(1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNPlayer(Player):\n",
    "    def __init__(self, model, color):\n",
    "        super().__init__(color)\n",
    "        assert color == Color.BLUE, \"DQNPlayer only supports blue\"\n",
    "        self.model = model\n",
    "        self.model.eval()\n",
    "\n",
    "    def decide(self, game, valid_actions):\n",
    "        state = state_tensor(game.state)\n",
    "        action_ints = list(map(to_action_space, valid_actions))\n",
    "        with torch.no_grad():\n",
    "            Q = self.model(state)[0, action_ints]\n",
    "        best_action = action_ints[Q.max(0).indices.item()]\n",
    "        return from_action_space(best_action, valid_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:59<00:00,  1.67it/s]\n"
     ]
    }
   ],
   "source": [
    "players = [\n",
    "    RandomPlayer(Color.ORANGE),\n",
    "    DQNPlayer(policy_net, Color.BLUE),\n",
    "]\n",
    "\n",
    "winners = []\n",
    "for i in tqdm(range(100)):\n",
    "    game = Game(players)\n",
    "    winners.append(game.play())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "winners.count(Color.BLUE) / len(winners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(policy_net.state_dict(), \"policy_net.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
